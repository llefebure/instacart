{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import *\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(TRAIN)\n",
    "test = pd.read_pickle(TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 70/30 train/validation split of the training data and also a small sample to speed up testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_set = (train[[\"user_id\"]]\n",
    "           .drop_duplicates()\n",
    "           .assign(val_flag = True)\n",
    "           .sample(frac = .3, random_state = 152)\n",
    "           .set_index(\"user_id\"))\n",
    "val_bool = train[[\"user_id\"]].join(val_set, on = \"user_id\")[[\"val_flag\"]].notnull()\n",
    "train.eval_set[val_bool.val_flag.values] = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_small = (train[train.eval_set == \"train\"][[\"user_id\"]]\n",
    "                   .drop_duplicates()\n",
    "                   .assign(small_flag = True)\n",
    "                   .sample(frac = .2, random_state = 152)\n",
    "                   .set_index(\"user_id\"))\n",
    "small_bool = train[[\"user_id\"]].join(train_set_small, on = \"user_id\")[[\"small_flag\"]].notnull()\n",
    "train.eval_set[small_bool.small_flag.values] = \"train_small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>73477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_small</th>\n",
       "      <td>18369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>39363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id\n",
       "eval_set            \n",
       "train          73477\n",
       "train_small    18369\n",
       "val            39363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"eval_set\").agg({\"user_id\": \"nunique\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score_per_order(truth_str, pred_str):\n",
    "    truth_set = set(truth_str.split())\n",
    "    pred_set = set(pred_str.split())\n",
    "    tp = len(truth_set & pred_set)\n",
    "    if tp == 0:\n",
    "        return 0.\n",
    "    p = 1. * tp / len(pred_set)\n",
    "    r = 1. * tp / len(truth_set)\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(truth_list, pred_list):\n",
    "    return np.mean([f1_score_per_order(x, y) for x, y in zip(truth_list, pred_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collapse(x):\n",
    "    product_list = filter(lambda y: y != \"\", x)\n",
    "    if len(product_list) == 0:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        return \" \".join(map(str, product_list))\n",
    "\n",
    "def binaryPredictionToString(X, preds, thr):\n",
    "    mat = X[[\"order_id\", \"product_id\"]]\n",
    "    mat = mat.assign(products = map(lambda (pid, pr): \"\" if pr < thr else pid,\n",
    "                                    zip(mat.product_id, preds)))\n",
    "    preds_str = mat.groupby(\"order_id\").agg({\n",
    "        \"products\": collapse\n",
    "    })\n",
    "    return preds_str\n",
    "    \n",
    "def evaluate(X, y, preds, thr = [.13, .15, .17, .19, .21, .23]):\n",
    "    truth_str = binaryPredictionToString(X, y, .5)\n",
    "    rv = dict()\n",
    "    for t in thr:\n",
    "        pred_str = binaryPredictionToString(X, preds, t)\n",
    "        rv[t] = f1_score(truth_str.values.flatten(), pred_str.values.flatten())\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildDMatrix(X, y = None):\n",
    "    cols_to_drop = [\"user_id\", \"order_id\", \"product_id\", \"eval_set\", \"ordered\"]\n",
    "    cols_to_drop_present = list(set(cols_to_drop) & set(X.columns.values))\n",
    "    X_dr = X.drop(cols_to_drop_present, axis = 1)\n",
    "    if y is not None:\n",
    "        dm = xgb.DMatrix(\n",
    "            X_dr.values, label = y.values, feature_names = X_dr.columns.values)\n",
    "    else:\n",
    "        dm = xgb.DMatrix(\n",
    "            X_dr.values, feature_names = X_dr.columns.values)\n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(X, y, X_test, y_test = None, model_params = {}, num_boost_round = 80):\n",
    "    \n",
    "    # Build DMatrices\n",
    "    train_dm = buildDMatrix(X, y)\n",
    "    if X_test is not None:\n",
    "        test_dm = buildDMatrix(X_test, y_test)\n",
    "    \n",
    "    # Fit model\n",
    "    model = xgb.train(model_params, train_dm, num_boost_round = num_boost_round)\n",
    "    \n",
    "    # Get training predictions\n",
    "    train_predictions = model.predict(train_dm)\n",
    "    \n",
    "    # Get test predictions\n",
    "    if X_test is not None:\n",
    "        test_predictions = model.predict(test_dm)\n",
    "    \n",
    "    # Evaluate on train\n",
    "    train_scores = evaluate(X, y, train_predictions)\n",
    "    \n",
    "    # If test labels known, evaluate on test\n",
    "    test_scores = None\n",
    "    if y_test is not None:\n",
    "        test_scores = evaluate(X_test, y_test, test_predictions)\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"train_f1_scores\": train_scores,\n",
    "        \"test_f1_scores\": test_scores,\n",
    "        \"test_predictions\": test_predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"objective\": \"reg:logistic\",\n",
    "  \"eval_metric\": \"logloss\",\n",
    "  \"eta\": 0.1,\n",
    "  \"max_depth\": 6,\n",
    "  \"min_child_weight\": 10,\n",
    "  \"gamma\": 0.70,\n",
    "  \"subsample\": 0.76,\n",
    "  \"colsample_bytree\": 0.95,\n",
    "  \"alpha\": 2e-05,\n",
    "  \"lambda\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train[train.eval_set != \"val\"]\n",
    "y_train = train.ordered[train.eval_set != \"val\"]\n",
    "X_test = train[train.eval_set == \"val\"]\n",
    "y_test = train.ordered[train.eval_set == \"val\"]\n",
    "model_train = trainModel(\n",
    "    X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Training F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threshold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.13</th>\n",
       "      <td>0.362066</td>\n",
       "      <td>0.364615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.370241</td>\n",
       "      <td>0.372789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.17</th>\n",
       "      <td>0.374770</td>\n",
       "      <td>0.378011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.19</th>\n",
       "      <td>0.376356</td>\n",
       "      <td>0.380186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.21</th>\n",
       "      <td>0.375757</td>\n",
       "      <td>0.379792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.23</th>\n",
       "      <td>0.373011</td>\n",
       "      <td>0.377306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Test F1  Training F1\n",
       "Threshold                       \n",
       "0.13       0.362066     0.364615\n",
       "0.15       0.370241     0.372789\n",
       "0.17       0.374770     0.378011\n",
       "0.19       0.376356     0.380186\n",
       "0.21       0.375757     0.379792\n",
       "0.23       0.373011     0.377306"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Threshold\": model_train[\"train_f1_scores\"].keys(),\n",
    "    \"Training F1\": model_train[\"train_f1_scores\"].values(),\n",
    "    \"Test F1\": model_train[\"test_f1_scores\"].values()\n",
    "}).set_index(\"Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = evaluate(\n",
    "    X_test, y_test, model_train[\"test_predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model_train[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = train\n",
    "# y_train = train.ordered\n",
    "# X_test = test\n",
    "# y_test = None\n",
    "# model_train = trainModel(\n",
    "#     X_train, y_train, X_test, y_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_str = binaryPredictionToString(X_test, model_train[\"test_predictions\"], .21)\n",
    "# pred_str.to_csv(\"./data/initial_model.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
